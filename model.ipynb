{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":142598,"sourceType":"datasetVersion","datasetId":3151}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:45:02.371151Z","iopub.execute_input":"2024-01-08T22:45:02.371517Z","iopub.status.idle":"2024-01-08T22:45:21.745450Z","shell.execute_reply.started":"2024-01-08T22:45:02.371485Z","shell.execute_reply":"2024-01-08T22:45:21.744364Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation\n  Cloning https://github.com/KinWaiCheuk/nnAudio.git to /tmp/pip-req-build-e4ig8864\n  Running command git clone --filter=blob:none --quiet https://github.com/KinWaiCheuk/nnAudio.git /tmp/pip-req-build-e4ig8864\n  Resolved https://github.com/KinWaiCheuk/nnAudio.git to commit ef941aff84a0c1a97456093044e8d318b5f49ade\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from nnAudio==0.3.2) (1.11.4)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.10/site-packages (from nnAudio==0.3.2) (1.24.3)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from nnAudio==0.3.2) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->nnAudio==0.3.2) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->nnAudio==0.3.2) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->nnAudio==0.3.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->nnAudio==0.3.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->nnAudio==0.3.2) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->nnAudio==0.3.2) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->nnAudio==0.3.2) (1.3.0)\nBuilding wheels for collected packages: nnAudio\n  Building wheel for nnAudio (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nnAudio: filename=nnAudio-0.3.2-py3-none-any.whl size=43594 sha256=01e88d9711f6ac97063e3b5be9511f49014452e9040b606feb2f7ab9c3f3f98a\n  Stored in directory: /tmp/pip-ephem-wheel-cache-gecasybw/wheels/1d/a5/c7/323cb6cb45785232ac4ec085a130ec5a5642be599143dd5a17\nSuccessfully built nnAudio\nInstalling collected packages: nnAudio\nSuccessfully installed nnAudio-0.3.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install einops","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:45:21.747627Z","iopub.execute_input":"2024-01-08T22:45:21.747921Z","iopub.status.idle":"2024-01-08T22:45:34.273652Z","shell.execute_reply.started":"2024-01-08T22:45:21.747895Z","shell.execute_reply":"2024-01-08T22:45:34.272435Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting einops\n  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.7.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install timm","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:45:34.275462Z","iopub.execute_input":"2024-01-08T22:45:34.275770Z","iopub.status.idle":"2024-01-08T22:45:46.459280Z","shell.execute_reply.started":"2024-01-08T22:45:34.275746Z","shell.execute_reply":"2024-01-08T22:45:46.458205Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.12)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.15.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.66.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.24.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:45:46.460730Z","iopub.execute_input":"2024-01-08T22:45:46.461018Z","iopub.status.idle":"2024-01-08T22:45:58.357186Z","shell.execute_reply.started":"2024-01-08T22:45:46.460994Z","shell.execute_reply":"2024-01-08T22:45:58.355997Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.2.1)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.24.3)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.0.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.10.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:45:58.360873Z","iopub.execute_input":"2024-01-08T22:45:58.361221Z","iopub.status.idle":"2024-01-08T22:46:10.421274Z","shell.execute_reply.started":"2024-01-08T22:45:58.361193Z","shell.execute_reply":"2024-01-08T22:46:10.420052Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\nhttps://github.com/YuanGongND/ast/blob/master/src/models/ast_models.py\nhttps://arxiv.org/pdf/2104.01778.pdf\nhttps://arxiv.org/pdf/2010.11929.pdf","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchaudio\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport os\nfrom nnAudio import features\nimport numpy as np\nimport math\nfrom einops import rearrange, reduce, asnumpy, parse_shape\nfrom einops.layers.torch import Rearrange, Reduce\nfrom timm.models.vision_transformer import Mlp, PatchEmbed , _cfg\nfrom timm.models.layers import DropPath, to_2tuple, trunc_normal_\nfrom torchmetrics.classification import Accuracy\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-08T22:46:10.422772Z","iopub.execute_input":"2024-01-08T22:46:10.423080Z","iopub.status.idle":"2024-01-08T22:46:17.970212Z","shell.execute_reply.started":"2024-01-08T22:46:10.423054Z","shell.execute_reply":"2024-01-08T22:46:17.969191Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# sample_audio, sr = torchaudio.load('/kaggle/input/audioset/train_wav/-0DLPzsiXXE.wav')","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:17.971595Z","iopub.execute_input":"2024-01-08T22:46:17.971946Z","iopub.status.idle":"2024-01-08T22:46:17.977507Z","shell.execute_reply.started":"2024-01-08T22:46:17.971915Z","shell.execute_reply":"2024-01-08T22:46:17.976421Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# sample_audio = sample_audio.mean(0)[:sr * 10].unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:17.979000Z","iopub.execute_input":"2024-01-08T22:46:17.979376Z","iopub.status.idle":"2024-01-08T22:46:17.987571Z","shell.execute_reply.started":"2024-01-08T22:46:17.979345Z","shell.execute_reply":"2024-01-08T22:46:17.986703Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# sample_audio.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:17.988773Z","iopub.execute_input":"2024-01-08T22:46:17.989669Z","iopub.status.idle":"2024-01-08T22:46:17.995648Z","shell.execute_reply.started":"2024-01-08T22:46:17.989636Z","shell.execute_reply":"2024-01-08T22:46:17.994868Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# sr","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:17.996759Z","iopub.execute_input":"2024-01-08T22:46:17.997081Z","iopub.status.idle":"2024-01-08T22:46:18.003731Z","shell.execute_reply.started":"2024-01-08T22:46:17.997051Z","shell.execute_reply":"2024-01-08T22:46:18.002884Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def pair(t):\n    return t if isinstance(t, tuple) else (t, t)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.004961Z","iopub.execute_input":"2024-01-08T22:46:18.005380Z","iopub.status.idle":"2024-01-08T22:46:18.011986Z","shell.execute_reply.started":"2024-01-08T22:46:18.005347Z","shell.execute_reply":"2024-01-08T22:46:18.011191Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"256*3","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.013259Z","iopub.execute_input":"2024-01-08T22:46:18.014087Z","iopub.status.idle":"2024-01-08T22:46:18.023702Z","shell.execute_reply.started":"2024-01-08T22:46:18.014055Z","shell.execute_reply":"2024-01-08T22:46:18.022790Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}]},{"cell_type":"code","source":"class PatchEmbedding(nn.Module):\n    \"\"\"\n    Slight modification of PatchEmbeding introduced in ViT\n    in_channels = 3 in the original paper but here spectrogram (the image) is 1-dimensional\n    \"\"\"\n    def __init__(self, fstride=10, tstride=10, patch_size = 16, emb_size = 768):\n        super().__init__()\n        self.patch_size = patch_size\n        self.projection = nn.Conv2d(in_channels = 1, out_channels = emb_size, \n                                    kernel_size = (patch_size, patch_size), stride = (fstride,tstride))\n    def gen_maskid_frame(self, num_patches_to_mask=3):\n        mask_id = random.sample(range(0, self.num_patches), num_patches_to_mask)\n        return mask_id\n    \n    def forward(self, x):\n        x = self.projection(x).flatten(2).transpose(1, 2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.027309Z","iopub.execute_input":"2024-01-08T22:46:18.027913Z","iopub.status.idle":"2024-01-08T22:46:18.036284Z","shell.execute_reply.started":"2024-01-08T22:46:18.027880Z","shell.execute_reply":"2024-01-08T22:46:18.035338Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = qk_scale or head_dim ** -0.5\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(proj_drop)\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        q = q * self.scale\n\n        attn = (q @ k.transpose(-2, -1))\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_drop(attn)\n\n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.041177Z","iopub.execute_input":"2024-01-08T22:46:18.041611Z","iopub.status.idle":"2024-01-08T22:46:18.052148Z","shell.execute_reply.started":"2024-01-08T22:46:18.041585Z","shell.execute_reply":"2024-01-08T22:46:18.051210Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm,Attention_block = Attention,Mlp_block=Mlp\n                 ,init_values=1e-4):\n        super().__init__()\n        self.norm1 = norm_layer(dim)\n        self.attn = Attention_block(\n            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp_block(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n\n    def forward(self, x):\n        x = x + self.drop_path(self.attn(self.norm1(x)))\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n        return x ","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.053206Z","iopub.execute_input":"2024-01-08T22:46:18.053528Z","iopub.status.idle":"2024-01-08T22:46:18.063372Z","shell.execute_reply.started":"2024-01-08T22:46:18.053484Z","shell.execute_reply":"2024-01-08T22:46:18.062429Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class MEASTModel(nn.Module):\n    # Adapted from https://github.com/YuanGongND/ast\n    \"\"\"\n    The Memory-Efficient Audio Spectrogram Tranformer Model.\n    \"\"\"\n    def __init__(self, depth = 12, audio_length = 10, label_dim=527, sr = 44100, fstride=10, tstride=10, input_fdim=128, num_heads = 8, embedding_dim = 768):\n        super().__init__()\n        self.input_tdim = fstride * tstride * audio_length\n        f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, self.input_tdim)\n        num_patches = f_dim * t_dim\n        self.num_patches = num_patches\n        self.embedding_dim = embedding_dim\n        self.spec_layer = features.MelSpectrogram(n_mels = input_fdim, win_length = 25, \n                                             hop_length = sr // (fstride * tstride) - 4, \n                                             center=False, sr=sr, pad_mode = \"same\", \n                                             trainable_mel = True)\n        self.patch_embedding = PatchEmbedding(fstride=fstride, tstride=tstride)\n        self.pos_embedding = nn.Parameter(torch.zeros(1, self.num_patches + 2, self.embedding_dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embedding_dim))\n        self.dist_token = nn.Parameter(torch.randn(1, 1, self.embedding_dim))\n        self.blocks = nn.ModuleList([Block(dim=self.embedding_dim, num_heads=12) for i in range(depth)])\n        self.pos_drop = nn.Dropout()\n        self.dropout = nn.Dropout()\n        self.norm = nn.LayerNorm(self.embedding_dim) #if not use_fc_norm else nn.Identity()\n        self.mlp_head = nn.Sequential(nn.LayerNorm(self.embedding_dim), nn.Linear(self.embedding_dim, label_dim))\n        \n    def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=1024):\n        test_input = torch.randn(1, input_fdim, input_tdim)\n        test_proj = nn.Conv2d(1, 3* (16 ** 3), kernel_size=(16, 16), stride=(fstride, tstride))\n        test_out = test_proj(test_input)\n        f_dim = test_out.shape[1]\n        t_dim = test_out.shape[2]\n        return f_dim, t_dim\n\n    def forward(self, x):\n        \"\"\"\n        :param x: the input spectrogram, expected shape: (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n        :return: prediction\n        \"\"\"\n        # expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n        #x = x.unsqueeze(1)\n        B = x.shape[0]\n        #print(x.shape) torch.Size([12, 1, 220500])\n        x = self.spec_layer(x)\n        #print(x.shape) torch.Size([12, 128, 500])\n        x = x.mT.unsqueeze(1)\n        #print(x.shape) torch.Size([12, 1, 500, 128])\n        x = self.patch_embedding(x)\n        # print(x.shape) torch.Size([12, 588, 768])\n        #x = x.unsqueeze(0) #.flatten(2) #.mT\n        # print(x.shape) #torch.Size([1, 451584, 12])\n        cls_tokens = self.cls_token.expand(B, -1, -1)\n        dist_token = self.dist_token.expand(B, -1, -1)\n        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n        x = x + self.pos_embedding\n        x = self.pos_drop(x)\n        for blk in self.blocks:\n            x = blk(x)\n        x = self.norm(x)\n        x = torch.mean(x, dim = 1)\n        x = self.mlp_head(x)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.064528Z","iopub.execute_input":"2024-01-08T22:46:18.064856Z","iopub.status.idle":"2024-01-08T22:46:18.082392Z","shell.execute_reply.started":"2024-01-08T22:46:18.064832Z","shell.execute_reply":"2024-01-08T22:46:18.081530Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py#L494\n","metadata":{}},{"cell_type":"code","source":"batch_size = 12\ndevice = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.085195Z","iopub.execute_input":"2024-01-08T22:46:18.085526Z","iopub.status.idle":"2024-01-08T22:46:18.092778Z","shell.execute_reply.started":"2024-01-08T22:46:18.085493Z","shell.execute_reply":"2024-01-08T22:46:18.091934Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class AudioSet(Dataset):\n    def __init__(self, root_dir, filenames, transform=None):\n        self.root_dir = root_dir\n        self.filenames = filenames\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        file_name = self.filenames[idx]\n        label = file_name.split('-')[-1].split('.')[0]\n        file_path = f'{self.root_dir}/{file_name}'\n        waveform, sample_rate = torchaudio.load(file_path)\n        if self.transform:\n            sample = self.transform(input_freq = sample_rate)(waveform)\n        return {'audio': sample, 'label' : torch.tensor(int(label), dtype = torch.float32)}","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.094056Z","iopub.execute_input":"2024-01-08T22:46:18.094381Z","iopub.status.idle":"2024-01-08T22:46:18.103314Z","shell.execute_reply.started":"2024-01-08T22:46:18.094351Z","shell.execute_reply":"2024-01-08T22:46:18.102438Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('/kaggle/input/environmental-sound-classification-50/audio/audio/'))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.104575Z","iopub.execute_input":"2024-01-08T22:46:18.104900Z","iopub.status.idle":"2024-01-08T22:46:18.177232Z","shell.execute_reply.started":"2024-01-08T22:46:18.104870Z","shell.execute_reply":"2024-01-08T22:46:18.176127Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"2002"},"metadata":{}}]},{"cell_type":"code","source":"class AudioProcessing(torch.nn.Module):\n    def __init__(\n        self,\n        input_freq = None,\n        resample_freq=44100\n    ):\n        super().__init__()\n        self.resample = T.Resample(orig_freq=input_freq, new_freq=resample_freq)\n        self.sr = input_freq\n\n    def forward(self, waveform):\n        waveform = waveform.mean(0)[:self.sr * 5].unsqueeze(0)\n        resampled = self.resample(waveform)\n        return resampled","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.178533Z","iopub.execute_input":"2024-01-08T22:46:18.178892Z","iopub.status.idle":"2024-01-08T22:46:18.188367Z","shell.execute_reply.started":"2024-01-08T22:46:18.178860Z","shell.execute_reply":"2024-01-08T22:46:18.187454Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/environmental-sound-classification-50/esc50.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.189604Z","iopub.execute_input":"2024-01-08T22:46:18.190049Z","iopub.status.idle":"2024-01-08T22:46:18.210241Z","shell.execute_reply.started":"2024-01-08T22:46:18.190017Z","shell.execute_reply":"2024-01-08T22:46:18.209369Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.211728Z","iopub.execute_input":"2024-01-08T22:46:18.212080Z","iopub.status.idle":"2024-01-08T22:46:18.230240Z","shell.execute_reply.started":"2024-01-08T22:46:18.212049Z","shell.execute_reply":"2024-01-08T22:46:18.229226Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"            filename  fold  target        category  esc10  src_file take\n0   1-100032-A-0.wav     1       0             dog   True    100032    A\n1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>fold</th>\n      <th>target</th>\n      <th>category</th>\n      <th>esc10</th>\n      <th>src_file</th>\n      <th>take</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1-100032-A-0.wav</td>\n      <td>1</td>\n      <td>0</td>\n      <td>dog</td>\n      <td>True</td>\n      <td>100032</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1-100038-A-14.wav</td>\n      <td>1</td>\n      <td>14</td>\n      <td>chirping_birds</td>\n      <td>False</td>\n      <td>100038</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1-100210-A-36.wav</td>\n      <td>1</td>\n      <td>36</td>\n      <td>vacuum_cleaner</td>\n      <td>False</td>\n      <td>100210</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1-100210-B-36.wav</td>\n      <td>1</td>\n      <td>36</td>\n      <td>vacuum_cleaner</td>\n      <td>False</td>\n      <td>100210</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1-101296-A-19.wav</td>\n      <td>1</td>\n      <td>19</td>\n      <td>thunderstorm</td>\n      <td>False</td>\n      <td>101296</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"msk = np.random.rand(len(df)) < 0.8\ntrain_df_pre = df[msk].reset_index(drop=True)\ntest_df = df[~msk]","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.231520Z","iopub.execute_input":"2024-01-08T22:46:18.231912Z","iopub.status.idle":"2024-01-08T22:46:18.241287Z","shell.execute_reply.started":"2024-01-08T22:46:18.231878Z","shell.execute_reply":"2024-01-08T22:46:18.240321Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_df = train_df_pre.sample(frac=0.8,random_state=200).reset_index(drop=True)\nvalid_df = train_df_pre.drop(train_df.index).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.242756Z","iopub.execute_input":"2024-01-08T22:46:18.243083Z","iopub.status.idle":"2024-01-08T22:46:18.253476Z","shell.execute_reply.started":"2024-01-08T22:46:18.243052Z","shell.execute_reply":"2024-01-08T22:46:18.252530Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"root_dir = '/kaggle/input/environmental-sound-classification-50/audio/audio/44100'","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.254629Z","iopub.execute_input":"2024-01-08T22:46:18.254894Z","iopub.status.idle":"2024-01-08T22:46:18.260115Z","shell.execute_reply.started":"2024-01-08T22:46:18.254871Z","shell.execute_reply":"2024-01-08T22:46:18.259052Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dataset = AudioSet(root_dir = root_dir,\n                         filenames = train_df['filename'],\n                         transform = AudioProcessing)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.261628Z","iopub.execute_input":"2024-01-08T22:46:18.262122Z","iopub.status.idle":"2024-01-08T22:46:18.267984Z","shell.execute_reply.started":"2024-01-08T22:46:18.262091Z","shell.execute_reply":"2024-01-08T22:46:18.266990Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"valid_dataset = AudioSet(root_dir = root_dir,\n                        filenames = valid_df['filename'],\n                        transform = AudioProcessing)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.269732Z","iopub.execute_input":"2024-01-08T22:46:18.270115Z","iopub.status.idle":"2024-01-08T22:46:18.276820Z","shell.execute_reply.started":"2024-01-08T22:46:18.270083Z","shell.execute_reply":"2024-01-08T22:46:18.276018Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_dataset = AudioSet(root_dir = root_dir,\n                        filenames = test_df['filename'],\n                        transform = AudioProcessing)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.277704Z","iopub.execute_input":"2024-01-08T22:46:18.278006Z","iopub.status.idle":"2024-01-08T22:46:18.285923Z","shell.execute_reply.started":"2024-01-08T22:46:18.277976Z","shell.execute_reply":"2024-01-08T22:46:18.285043Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\ntest_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.287018Z","iopub.execute_input":"2024-01-08T22:46:18.287988Z","iopub.status.idle":"2024-01-08T22:46:18.296798Z","shell.execute_reply.started":"2024-01-08T22:46:18.287942Z","shell.execute_reply":"2024-01-08T22:46:18.295817Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_dl","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.298066Z","iopub.execute_input":"2024-01-08T22:46:18.298332Z","iopub.status.idle":"2024-01-08T22:46:18.305743Z","shell.execute_reply.started":"2024-01-08T22:46:18.298310Z","shell.execute_reply":"2024-01-08T22:46:18.304836Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7f9a04e45660>"},"metadata":{}}]},{"cell_type":"code","source":"print(len(train_dataset))\nprint(len(valid_dataset))\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.306964Z","iopub.execute_input":"2024-01-08T22:46:18.307271Z","iopub.status.idle":"2024-01-08T22:46:18.313692Z","shell.execute_reply.started":"2024-01-08T22:46:18.307247Z","shell.execute_reply":"2024-01-08T22:46:18.312834Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"1310\n328\n362\n","output_type":"stream"}]},{"cell_type":"code","source":"x = next(iter(train_dl))['audio']","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.314781Z","iopub.execute_input":"2024-01-08T22:46:18.315056Z","iopub.status.idle":"2024-01-08T22:46:18.549532Z","shell.execute_reply.started":"2024-01-08T22:46:18.315033Z","shell.execute_reply":"2024-01-08T22:46:18.548483Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = MEASTModel(label_dim = 50, audio_length = 5).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:18.553464Z","iopub.execute_input":"2024-01-08T22:46:18.553792Z","iopub.status.idle":"2024-01-08T22:46:19.723168Z","shell.execute_reply.started":"2024-01-08T22:46:18.553765Z","shell.execute_reply":"2024-01-08T22:46:19.722257Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"STFT kernels created, time used = 0.0979 seconds\nSTFT filter created, time used = 0.0045 seconds\nMel filter created, time used = 0.0045 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4) # use smaller lr\naccuracy = Accuracy(task=\"multiclass\", num_classes=50).to(device)\nnum_epochs = 100\n\nfor epoch in range(num_epochs):    \n    # Get the next batch from seq_dl\n    train_loss = 0.0\n    train_acc = 0.0\n    total = 0\n    for batch in tqdm(train_dl):\n        batch['label'] = batch['label'].type(torch.LongTensor) \n        batch_x = batch['audio'].to(device)\n        batch_y = batch['label'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(batch_x)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        train_acc += accuracy(outputs, batch_y) * len(batch_x)\n        total += len(batch_x)\n\n    print(f'Epoch {epoch} loss: {train_loss:.4f} train_acc : {train_acc/total:.4f}')\n            \n    valid_acc = 0.0\n    total = 0\n    with torch.no_grad():\n        for batch in tqdm(valid_dl):\n            batch['label'] = batch['label'].type(torch.LongTensor) \n            batch_x = batch['audio'].to(device)\n            batch_y = batch['label'].to(device)\n            outputs = model(batch_x)\n            \n            valid_acc += accuracy(outputs, batch_y) * len(batch_x)\n            total += len(batch_x)\n            \n        print(f\"valid_acc: {valid_acc/total:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-08T22:46:19.724413Z","iopub.execute_input":"2024-01-08T22:46:19.724834Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5518edcf7e64d2eb3f55d30e1b75387"}},"metadata":{}},{"name":"stdout","text":"Epoch 0 loss: 438.8759 train_acc : 0.0374\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb11e9659ab42ab8c0c29b6232134f0"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.0518\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88570f08ec34cbda34bd55b3a80788c"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 loss: 400.3102 train_acc : 0.0496\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c512082a1b1f482288eda55bd8921f41"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.0854\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008ed029f943432fa9f26a360ae73a0c"}},"metadata":{}},{"name":"stdout","text":"Epoch 2 loss: 364.0918 train_acc : 0.1015\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c109346e1ba14a4588a2a3859400ec69"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.1677\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62263528a6a34845986e1bf7555413a1"}},"metadata":{}},{"name":"stdout","text":"Epoch 3 loss: 328.5469 train_acc : 0.1489\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4f6951b1f74afea7d4a7ea0dbb8350"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.1463\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37e2994a0e4e41eba4da18a4f50c1c1b"}},"metadata":{}},{"name":"stdout","text":"Epoch 4 loss: 311.5104 train_acc : 0.1794\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ab077369ed499cab8ec3f4c6b12541"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.2104\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a51d0733c14d05adafbf7cf06ce7a4"}},"metadata":{}},{"name":"stdout","text":"Epoch 5 loss: 296.9802 train_acc : 0.2160\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c61bb70daa44cc972c80cf7b4b1992"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.2256\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a7d07bb3744d2682aeeedba324506e"}},"metadata":{}},{"name":"stdout","text":"Epoch 6 loss: 283.1974 train_acc : 0.2366\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea6ec94957284dd4a9b5bc82a0f72c84"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.2622\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59fd842737e84090b5fdd73de1a4852f"}},"metadata":{}},{"name":"stdout","text":"Epoch 7 loss: 273.9235 train_acc : 0.2740\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd10c6e646b44ff19013403ea568d41b"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.2530\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"206333b8b0374e11b602cb7055ff5ba1"}},"metadata":{}},{"name":"stdout","text":"Epoch 8 loss: 252.8522 train_acc : 0.3076\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b45c2f20124a33a914e5ac7b856483"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.3384\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0105f68baf0b41d2b713f2d7d0737b62"}},"metadata":{}},{"name":"stdout","text":"Epoch 9 loss: 245.2798 train_acc : 0.3130\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55b816a06f041d5b91ad00061f5b057"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.3750\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a97654b3a0242119334e1dd582be9d6"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 loss: 228.0502 train_acc : 0.3534\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffc4b9141ecd468cb8d877d675bc275c"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.3750\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef800f57f215423080d15b145cf55c41"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 loss: 207.4671 train_acc : 0.4061\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"304c10ba95704ab1aefec31601d2be5a"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.3872\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a432937c208a45aa91647d2b293f0d25"}},"metadata":{}},{"name":"stdout","text":"Epoch 12 loss: 193.5060 train_acc : 0.4351\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a125e3a05daf4ba0ae76b8d601f3e661"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.5274\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153b53ee39bd4e41a41dda8503247236"}},"metadata":{}},{"name":"stdout","text":"Epoch 13 loss: 173.2101 train_acc : 0.5237\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49960bbcd791429794a026cbe627693f"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.4817\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e7c9703e994cf9981da8c0ad736f3f"}},"metadata":{}},{"name":"stdout","text":"Epoch 14 loss: 158.6691 train_acc : 0.5550\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d906d6e1c42405aad8141347b6f3d1e"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.5152\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4caee80bf104e87a3f29caa6048ccde"}},"metadata":{}},{"name":"stdout","text":"Epoch 15 loss: 139.7247 train_acc : 0.6076\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5f78ab5c0514550b8d39ba9711f77d0"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.5579\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eddfc8fb50fb4a52ad68652a4b2112bf"}},"metadata":{}},{"name":"stdout","text":"Epoch 16 loss: 129.8934 train_acc : 0.6397\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70e084e8d9784a278ddd6b68093e20b7"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.6006\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b3b8973e844de984dfe6bf5c1f8351"}},"metadata":{}},{"name":"stdout","text":"Epoch 17 loss: 113.7242 train_acc : 0.6756\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa22d78bc12f44829026857937e167f5"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.6372\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a57831693867415b8623e83cb4408485"}},"metadata":{}},{"name":"stdout","text":"Epoch 18 loss: 102.5975 train_acc : 0.7000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f77783c9c21a4eb996f7762428719cf8"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.6677\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6cf593fa342452484b03141bbd868e9"}},"metadata":{}},{"name":"stdout","text":"Epoch 19 loss: 88.9324 train_acc : 0.7504\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9428c666d014201927d6df54fda5010"}},"metadata":{}},{"name":"stdout","text":"valid_acc: 0.7012\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/110 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06451be0e19546ccbdfefbd2931ecbd5"}},"metadata":{}}]}]}